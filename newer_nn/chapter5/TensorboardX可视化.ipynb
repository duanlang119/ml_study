{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "['add_audio',\n 'add_custom_scalars',\n 'add_custom_scalars_marginchart',\n 'add_custom_scalars_multilinechart',\n 'add_embedding',\n 'add_figure',\n 'add_graph',\n 'add_graph_deprecated',\n 'add_histogram',\n 'add_histogram_raw',\n 'add_hparams',\n 'add_image',\n 'add_image_with_boxes',\n 'add_images',\n 'add_mesh',\n 'add_onnx_graph',\n 'add_openvino_graph',\n 'add_pr_curve',\n 'add_pr_curve_raw',\n 'add_scalar',\n 'add_scalars',\n 'add_text',\n 'add_video',\n 'all_writers',\n 'close',\n 'default_bins',\n 'export_scalars_to_json',\n 'file_writer',\n 'flush',\n 'kwargs',\n 'logdir',\n 'purge_step',\n 'scalar_dict']"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets\n",
    "from tensorboardX import SummaryWriter\n",
    "import datetime\n",
    "writer = SummaryWriter()\n",
    "#有以下可用的方法\n",
    "list(filter(lambda x:False if x.startswith(\"_\") else True ,dir(writer)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 添加标量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#二十个step对应的损失\n",
    "losses = [1.3,1.23,1.19,1.1,1.098,1.02,0.98,0.87,0.67,0.43,0.23,0.12,0.12,0.109,0.09,0.0009,0.005,0.0006,0.00064,0.00006]\n",
    "for step in range(20):\n",
    "    #add_scalar方法将信息写入日志文件\n",
    "    writer.add_scalar(\"data/loss\",losses[step],step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 可视化图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 系统找不到指定的路径。: '../chapter4/DogVsCatData/train'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-4-09eb8c6ed85e>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      6\u001B[0m                                        \u001B[1;31m#,transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m                                       ])\n\u001B[1;32m----> 8\u001B[1;33m \u001B[0mtrain_data\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mImageFolder\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'../chapter4/DogVsCatData/train'\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0msimple_transform\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      9\u001B[0m \u001B[0mto_image\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtransforms\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mToPILImage\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m8\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda3\\envs\\pt38\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, root, transform, target_transform, loader, is_valid_file)\u001B[0m\n\u001B[0;32m    224\u001B[0m             \u001B[0mis_valid_file\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mOptional\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mCallable\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mstr\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbool\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    225\u001B[0m     ):\n\u001B[1;32m--> 226\u001B[1;33m         super(ImageFolder, self).__init__(root, loader, IMG_EXTENSIONS if is_valid_file is None else None,\n\u001B[0m\u001B[0;32m    227\u001B[0m                                           \u001B[0mtransform\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtransform\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    228\u001B[0m                                           \u001B[0mtarget_transform\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtarget_transform\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda3\\envs\\pt38\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001B[0m\n\u001B[0;32m    106\u001B[0m         super(DatasetFolder, self).__init__(root, transform=transform,\n\u001B[0;32m    107\u001B[0m                                             target_transform=target_transform)\n\u001B[1;32m--> 108\u001B[1;33m         \u001B[0mclasses\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mclass_to_idx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_find_classes\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mroot\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    109\u001B[0m         \u001B[0msamples\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmake_dataset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mroot\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mclass_to_idx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mextensions\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mis_valid_file\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    110\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msamples\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\Anaconda3\\envs\\pt38\\lib\\site-packages\\torchvision\\datasets\\folder.py\u001B[0m in \u001B[0;36m_find_classes\u001B[1;34m(self, dir)\u001B[0m\n\u001B[0;32m    135\u001B[0m             \u001B[0mNo\u001B[0m \u001B[1;32mclass\u001B[0m \u001B[1;32mis\u001B[0m \u001B[0ma\u001B[0m \u001B[0msubdirectory\u001B[0m \u001B[0mof\u001B[0m \u001B[0manother\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    136\u001B[0m         \"\"\"\n\u001B[1;32m--> 137\u001B[1;33m         \u001B[0mclasses\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0md\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mname\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0md\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mscandir\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdir\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0md\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mis_dir\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    138\u001B[0m         \u001B[0mclasses\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msort\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    139\u001B[0m         \u001B[0mclass_to_idx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m{\u001B[0m\u001B[0mcls_name\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mi\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcls_name\u001B[0m \u001B[1;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mclasses\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [WinError 3] 系统找不到指定的路径。: '../chapter4/DogVsCatData/train'"
     ]
    }
   ],
   "source": [
    "#数据加载\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms,utils,models,datasets\n",
    "simple_transform = transforms.Compose([transforms.Resize((120,120))\n",
    "                                       ,transforms.ToTensor()\n",
    "                                       #,transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                      ])\n",
    "train_data = ImageFolder('../chapter4/DogVsCatData/train',simple_transform)\n",
    "to_image = transforms.ToPILImage()\n",
    "for i in range(8):\n",
    "    writer.add_image(\"data/Dog_Cat_Image_{}\".format(i),train_data[i][0],i)\n",
    "    writer.add_image_with_boxes('data/Dog_Cat_Image_with_box_{}'.format(i), train_data[i][0], \n",
    "                                torch.Tensor([[10, 10,100, 100]]), i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 添加音频"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    writer.add_audio(\"audio/audio_{}\".format(i),train_data[i][0].view(-1),i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 普通文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    writer.add_text('Text/Simple_Text', 'text logged at step:{}'.format(i), i)\n",
    "    writer.add_text('Text/Markdown_Text', '''a|b\\n-|-\\nc|d''',i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PR精度召回率曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_pr_curve('精度召回率曲线', np.random.randint(2, size=100), np.random.rand(100), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positive_counts = [75, 64, 21, 5, 0]\n",
    "false_positive_counts = [150, 105, 18, 0, 0]\n",
    "true_negative_counts = [0, 45, 132, 150, 150]\n",
    "false_negative_counts = [0, 11, 54, 70, 75]\n",
    "precision = [0.3333333, 0.3786982, 0.5384616, 1.0, 0.0]\n",
    "recall = [1.0, 0.8533334, 0.28, 0.0666667, 0.0]\n",
    "\n",
    "writer.add_pr_curve_raw('精度召回率曲线原始数据', true_positive_counts,\n",
    "                                false_positive_counts,\n",
    "                                true_negative_counts,\n",
    "                                false_negative_counts,\n",
    "                                precision,\n",
    "                                recall, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method add_pr_curve in module tensorboardX.writer:\n",
      "\n",
      "add_pr_curve(tag, labels, predictions, global_step=None, num_thresholds=127, weights=None, walltime=None) method of tensorboardX.writer.SummaryWriter instance\n",
      "    Adds precision recall curve.\n",
      "    \n",
      "    Args:\n",
      "        tag (string): Data identifier\n",
      "        labels (torch.Tensor, numpy.array, or string/blobname): Ground truth data. Binary label for each element.\n",
      "        predictions (torch.Tensor, numpy.array, or string/blobname):\n",
      "        The probability that an element be classified as true. Value should in [0, 1]\n",
      "        global_step (int): Global step value to record\n",
      "        num_thresholds (int): Number of thresholds used to draw the curve.\n",
      "        walltime (float): Optional override default walltime (time.time()) of event\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(writer.add_pr_curve)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导出数据到json文件，以便外部程序处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.export_scalars_to_json(\"./all_scalars.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 降维投影"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n",
      "warning: Embedding dir exists, did you set global_step for add_embedding()?\n"
     ]
    }
   ],
   "source": [
    "dataset = datasets.MNIST('mnist', train=False, download=True)\n",
    "images = dataset.test_data[:1000].float()\n",
    "labels = dataset.test_labels[:1000]\n",
    "features = images.view(1000, 784)\n",
    "writer.add_embedding(features, metadata=labels, label_img=images.unsqueeze(1))\n",
    "writer.add_embedding(features, global_step=1, tag='noMetadata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}